{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d2fc25",
   "metadata": {},
   "source": [
    "# Lasso Regression\n",
    "* Lasso Regression shares the same assumptions as OLS, but Lasso Regression is particularly useful for feature selection and dealing with high-dimensional data\n",
    "    * Linearity: There should be a linear relationship between the features and the target\n",
    "    * Independence of Errors: Errors (residuals) should be independent of each other. Patterns in a residual plot may suggest a lack of independence\n",
    "    * Homoscedasticity: Variance of errors should be constant. An example of heteroscedsticity (bad) is if you have a conal shape in your residual plot\n",
    "    * Normality of Errors: The errors should be normally distributed. Check the Q-Q plot - if the residuals are normally distributed, then the points should fall approximately along a straight line\n",
    "    * No perfect collinearity: Features are not perfectly correlated (perfect collinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51089aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5f2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=10000, n_features = 500, noise = 10, random_state = 42)\n",
    "feature_names = [\"feature \" + str(i) for i in range(1, len(X[0,:])+1)]\n",
    "X = pd.DataFrame(dict(zip(feature_names, np.transpose(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf3d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will split the data here\n",
    "# If you have access to a separate test set, treat this as validation to make sure your data satisfies the assumptions\n",
    "# of linear regression. Retrain on the entire dataset and then make predictions on the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96502f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scaled data for regularization so that all features are weighed equally\n",
    "\n",
    "# Import Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform X_train and X_test\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd02c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lasso alpha: 0.2301807986514151\n",
      "Training R-Squared: 0.9980\n",
      "Testing R-Squared: 0.9979\n",
      "Mean Squared Error: 99.6313\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression on the scaled data\n",
    "model = LassoCV(cv = 5, random_state = 42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(f\"Best Lasso alpha: {model.alpha_}\")\n",
    "print(f\"Training R-Squared: {model.score(X_train_scaled, y_train):.4f}\")\n",
    "print(f\"Testing R-Squared: {model.score(X_test_scaled, y_test):.4f}\")\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y_test, model.predict(X_test_scaled)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd2dd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 3: 0.22678032001195544\n",
      "feature 11: 83.55604152529011\n",
      "feature 13: 0.004163867856155918\n",
      "feature 32: -0.06700188386600144\n",
      "feature 57: -0.07283213918619315\n",
      "feature 88: 0.04528011865349032\n",
      "feature 110: 0.0440845295045865\n",
      "feature 133: 93.14766564327005\n",
      "feature 150: 0.025824777935323475\n",
      "feature 163: 0.02778617063519812\n",
      "feature 179: 62.569708169085885\n",
      "feature 209: 0.03621703231099764\n",
      "feature 240: 88.19968581895158\n",
      "feature 247: 40.601506314871855\n",
      "feature 299: -0.05123638207301383\n",
      "feature 304: -0.07041683689634096\n",
      "feature 305: 96.40956827729042\n",
      "feature 338: 0.005680273015467948\n",
      "feature 364: 33.326729197954286\n",
      "feature 368: -0.03981530959174944\n",
      "feature 376: 83.15722980251165\n",
      "feature 413: -0.0007360393469938345\n",
      "feature 435: 11.284603410570345\n",
      "feature 458: -0.04975307444701059\n",
      "feature 470: 63.407261940983695\n",
      "feature 493: 0.040553106765340935\n"
     ]
    }
   ],
   "source": [
    "# We can check which the coefficients for each feature and see which ones didn't dropped to 0\n",
    "feature_coef = dict(zip(X.columns, model.coef_))\n",
    "for feature in feature_coef.keys():\n",
    "    if feature_coef[feature] != 0:\n",
    "        print(f\"{feature}: {feature_coef[feature]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f6818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
